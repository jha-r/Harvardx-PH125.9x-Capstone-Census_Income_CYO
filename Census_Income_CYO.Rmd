---
title: "HavardX PH125.9x Data Science Capstone CYO Project Report"
author: "Ravi Jha"
date: "12/20/2019"
output:
  html_document: default
  pdf_document:
    df_print: kable
    toc: yes
    toc_depth: 4
  word_document:
    toc: yes
    toc_depth: '4'
---

```{r setup, include=FALSE}
    library(knitr)
    knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, 
                          cache.lazy = FALSE, fig.align='center', fig.width=6, fig.height=4.5)
```

\pagebreak

# 1. Introduction

### 1.1 Overview

This report is prepared to fulfill the completion requirement of the **HavardX PH125.9x Data Science Capstone** course. 
TBD

model to classify people using demographics to predict whether a person will have an annual income over 50K dollars or not.

### 1.2 Motivation
TBD

### 1.3 Project Goal

The goal of this project is to train machine learning algorithms that predicts whether income exceeds $50K/yr based on census data and then compare their performance.


### 1.4 Key steps performed

Following are the key steps performed in this project:

 * Importing the dataset and setup
 * Spliting datasets
 * Data wrangling
 * Exploratory data analysis and visualization 
 * Creating and tuning predective models
 * Evaluating models based on validation dataset
 * Reporting results 

\pagebreak

# 2. Data and setup

The first step in the whole process is to import and setup data including splitting it in appropriate sub-datasets. 

### 2.1 Adult Census Income DataSet

Let's start with the dataset, as per course instruction, Machine Learning analyses friendly **Adult Census Income** dataset, from UCI's curated list of datasets, is used. The data was extracted from the 1994 Census bureau database by Ronny Kohavi and Barry Becker (Data Mining and Visualization, Silicon Graphics). The dataset is then cleaned considering the following criteria: 

 - age > 16
 - adjusted gross income > $100
 - final weighting > 1
 - working hours per week > 0

This data set can be found and downloaded here:

* Adult Census Income dataset:           http://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data


### 2.2 Data Import and Initial Setup

To assist with our data import and initial setup, several packages from *CRAN* is utilized and loaded. These will be automatically downloaded and installed during code execution. 


```{r data import and initial setup}
##########################
# to import and setup data
##########################
# Install requested packages if not found
if (!require(tidyverse))
  install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if (!require(caret))
  install.packages("caret", repos = "http://cran.us.r-project.org")
if (!require(data.table))
  install.packages("data.table", repos = "http://cran.us.r-project.org")
if (!require(dplyr))
  install.packages("dplyr")
if (!require(tidyr))
  install.packages("tidyr")
if (!require(e1071))
  install.packages("e1071", , dependencies=TRUE, 
                   repos = "http://cran.us.r-project.org")

# Load libraries
library(tidyverse)
library(caret)
library(e1071)
library(ggplot2)
library(randomForest)
library(hexbin)
library(lubridate)
library(knitr)
library(kableExtra)
# Adult Census Income dataset
# http://archive.ics.uci.edu/ml/machine-learning-databases/adult
datafile <- "Income.RData"
# Check if datafile is already downloaded
if (!file.exists("Income.RData"))
{
  fileURL <-
    "http://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data"
  
  destfile_adult <- "./dataset/adult.data"
  
  # Download only if destination data file - adult.data
  # is not found on the dataset directory folder
  if (!file.exists(destfile_adult))
  {
    # Create dataset folder file if it doesn't exists
    if (!dir.exists("./dataset"))
    {
      dir.create("./dataset")
    }
    
    # Download file from url to temp file
    download.file(fileURL, destfile_adult,  quiet = TRUE)
    print("Downloading file to the dataset directory")
    
  }
  
  c_names <-
    c(
      "age", "workclass", "fnlwgt", "education", "education-num", 
      "marital-status", "occupation", "relationship", "race", "sex", 
      "capital-gain", "capital-loss", "hours-per-week", "native-country", "income"
    )
  
  
  # read the data from the file and store in the census_data object
  census_data <-
    read.csv(file = "./dataset/adult.data", header = FALSE, 
             col.names = c_names, stringsAsFactors = T, strip.white = TRUE)
  
  # replace . in the columns names
  colnames(census_data) <- str_replace_all(colnames(census_data), "\\.", "_")
  
  # Save census_data object to datafile
  save(census_data, file = datafile)
  
  # Remove unused objects from the memory
  rm(c_names, fileURL, datafile, destfile_adult)
  
} else {
  # Load the datafile if it already exists
  load(datafile)
}
```



<br/>

\pagebreak

# 3. Data Wrangling

The next step is to understand the data through a brief data review and then do data wrangling as per the necessity.

### 3.1 Initial exploration

Before proceeding further with analysis, examining the data is important. The first step in it is to understand the format and the contents by looking at the few rows.

```{r Inital analysis-head}
    # Display first few rows to understand the data structure
    head(census_data, 5)%>%
    
    # to format table with theme
    kable() %>% 
    kable_styling(latex_options = c("striped", "hover", "condensed", "scale_down"))
```


<br/>

The dataset has 32,561 records and 15 attributes

```{r row_columns class, echo=FALSE}
    
    # to display class of userId and movieId column in a tabular form
      # to display number of rows and columns in a tabular form
      row_cols <- tibble(Rows = nrow(census_data), 
                             Columns = ncol(census_data))
      row_cols %>% 
      
      # to apply theme to the table
      kable() %>% 
      kable_styling(latex_options = c("striped", "hover", "condensed"))
``` 

<br/>


#### Dataset Summary 

```{r summary, include=TRUE}
    # Summary of the census_data_train dataset
    summary(census_data)%>%
    
    kable() %>% 
    kable_styling(latex_options = c("striped", "hover", "condensed", "scale_down"))
```

<br/>


#### Column types and class

Let's check column types and their class


```{r Columns}
    # To display dataset column types and summary
    col_type <- as.data.frame(lapply(census_data, class)) %>%
      .[1, ] %>%
      gather(variable, R_class , 1:ncol(.)) %>%
      mutate(data_type = ifelse(
        R_class == "factor",
        "categorical",
        ifelse(variable == "education_num", "categorical", "continuous")
      )) 

        col_type%>%
      
      # to format table with theme
      kable() %>%
      kable_styling(latex_options = c("striped", "hover", "condensed")) 
```


<br/>



<br/>

#### Factorizing Variables
# TBD
In the dataset, columns `userId` and `movieId` contains numeric data and treated as numeric/integer by R. These columns can be converted to factor as this could be used as categorical data; however, in the current scenario it makes more sense to leave it as numeric to keep later computation easier e.g. summarize() function and other numeric calculations can be done easily.

```{r userid-movieid class}
    # to factoring variables to exclude the unwanted levels
    census_data$workclass <- factor(census_data$workclass)
    census_data$occupation <- factor(census_data$occupation)
    census_data$native_country <- factor(census_data$native_country)

``` 


<br/>

### 3.2 Tidying data

Based on the initial understanding further data analysis is required to identify data cleaning necessities. Following are the steps to tidy the data:


#### Duplicate Records

Let's first check for any duplicate record. The following table shows there are 24 duplicate rows.

```{r duplicates}
    census_data %>%
      summarize(no_of_observations = n(),
                no_of_distinct = n_distinct(.)) %>%
      mutate(no_of_dup = no_of_observations - no_of_distinct) %>%
      mutate(pct_dup = round(no_of_dup / no_of_observations * 100, 1)) %>%
      # to format table with theme
      kable() %>%
      kable_styling(latex_options = c("striped", "hover", "condensed")) 

```


<br/>

#### Missing Data

By closely looking at the data, it can be observed that there are columns with value "?". This is also supported by the dataset details available on UCI wesite that **unknown** values are labelled as **?**. 

As it can be seen from the below table, there are 2,399 incomplete records (~7.4%). Specifically, there are missing values in occupation, workclass and native_country, which accounts for 5.7%, 5.6% and 1.8% of the total records respectively.

```{r missing data}
    #to check if any missing value marked with NA
      anyNA(census_data)
    
    # to check missing values labeled as "?"
    total_missing <-
      map_df(census_data, ~ str_detect(., pattern = "\\?")) %>%
      rowSums() %>%
      tbl_df() %>%
      filter(value > 0) %>%
      summarize(no_of_missing = n()) %>%
      filter(no_of_missing > 1) %>%
      mutate(pct_missing = round(no_of_missing / nrow(census_data) * 100, 1),
             variable = "all variables") %>%

      select(variable, no_of_missing, pct_missing)
    
    
    map_df(census_data, ~ sum(str_detect(., pattern = "\\?"))) %>%

      gather(variable, no_of_missing, 1:15) %>%
      mutate(pct_missing = round(no_of_missing / nrow(census_data) * 100, 1)) %>%
      bind_rows(total_missing) %>%
      filter(no_of_missing > 1) %>%
      arrange(desc(no_of_missing)) %>%
      # to format table with theme
      kable() %>%
      kable_styling(latex_options = c("striped", "hover", "condensed")) %>%
      row_spec(1:1, color = "white", background = "#D7261E")
```



#### Impute missing values

To prepare the dataset for analysis, getting rid if missing values in an important step. The method is by replacing the missing values with the mean for numerical variables; however, it makes more sense to remove records with missing values for categorical attribtes using the following code:


```{r impute_missing}
    # first to convert missing values ? to NA
    # for workclass, occupation, and native_country
    census_data$workclass<-ifelse(census_data$workclass=='?',
                                  NA, as.character(census_data$workclass))
    census_data$occupation<-ifelse(census_data$occupation=='?',
                                   NA, as.character(census_data$occupation))
    census_data$native_country<-ifelse(census_data$native_country=='?',
                                       NA, as.character(census_data$native_country))

    # next remove rows with missing values
    census_data <- na.omit(census_data)
    
```

<br/>


#### Education and Education_Num columns

`education` and `education_num` variables represents the same data with `education_num` as ordinal representation. We can get rid of `education_num` for cleaning the data using the following code:
 

```{r education_num}
    # to remove education_num column
    census_data <- census_data %>%
      select(-education_num)
```


<br/>

#### Capital Gain and Capital Loss columns

Next, the `capital_gain` and  `capital_loss` columns can be combined into a single colum `capital`. Further, `capital_gain` and  `capital_loss` columns can be removed to aid the analysis, using the following code:


```{r capital}
    # to combine capital gain and capital loss columns
    # into a single column Capital,
    # a positive value represents gain and negative represents loss
    census_data <- census_data %>%
      mutate(capital = capital_gain - capital_loss) %>%
      # then remove capital_gain and capital_loss
      select(-capital_gain, -capital_loss)
```


<br/>

#### Final Weight column

The final weight is represented by `fnlwgt` column, adjusts the weight as per population size of number of people in the census data.For example, a record gets a high weight if the proportion of such samples is comparatively small in the overall population and vice-versa. This is not useful in the analysis, hence, can be removed.


```{r fnlwgt}
    # to remove fnlwgt column
    census_data <- census_data %>%
      select(-fnlwgt)
```

#### Combine Marital Status column catagories

Next, cobmine `marital_status` column values into 3 categories - Married, Not-married, Never-married using the following code:


```{r marital_status}
    # to combine the column values catagories 
    census_data$marital_status <- as.character(census_data$marital_status)

    Married <- c("Married-AF-spouse", "Married-civ-spouse", "Married-spouse-absent")
    Notmarried <- c("Divorced","Separated", "Widowed")

    # to update the marital_status column with the new catagories    
    census_data$marital_status[census_data$marital_status %in% Married] <-
      "Married"
    census_data$marital_status[census_data$marital_status %in% Notmarried] <-
      "Not-married"
    

    # to display the table
    table(census_data$marital_status) %>%
      kable() %>%
      kable_styling(latex_options = c("striped", "hover", "condensed"))
```


#### Combine Native Country column catagories

There are too many categories in `native_country` column, it can be reduced to their regions and key countries.
The countries are categorized among their respective regions and leaving key countries such as the US to see if native to the countries make any difference to the income prediction.

```{r native_country}
    # to combine the column values catagories 

    LatinAmerica <- c("Dominican-Republic","Guatemala","Haiti","Honduras",
                      "Jamaica","Mexico","Nicaragua", "Outlying-US(Guam-USVI-etc)", 
                      "Puerto-Rico","Trinadad&Tobago","Cuba")

    SouthAmerica <- c("Peru","Ecuador","El-Salvador","Columbia")
    
    Europe <- c("France","Germany","Greece","Holand-Netherlands",
                "Hungary","Italy","Poland", "Portugal","Puerto-Rico",
                "South","Ireland","Yugoslavia")
    
    Asia <- c("China","Hong","India","Japan","Iran")
    
    SE_Aisa <- c("Vietnam","Cambodia","Thailand","Laos","Philippines","Taiwan")
    
    US <- c("United-States")
    UK <- c("England","Scotland")
    Canada <- c("Canada")

    # to update the native_country column with the new catagories    
    census_data$native_country[census_data$native_country %in% LatinAmerica] <-
      "Latin America"
    census_data$native_country[census_data$native_country %in% Asia] <-
      "Asia"
    census_data$native_country[census_data$native_country %in% SE_Aisa] <-
      "South East Aisa"
    census_data$native_country[census_data$native_country %in% SouthAmerica] <-
      "South America"
    census_data$native_country[census_data$native_country %in% Europe] <-
      "Europe"
    census_data$native_country[census_data$native_country %in% US] <-
      "US"
    census_data$native_country[census_data$native_country %in% UK] <-
      "UK"
    census_data$native_country[census_data$native_country %in% Canada] <-
      "Canada"

    # to display the data in a tabular form
    table(census_data$native_country) %>%
          kable() %>%
          kable_styling(latex_options = c("striped", "hover", "condensed"))
```

<br/>

#### Combine Education column catagories

Similarly, categories in `education` column can be combined into a fewer columns to make the modeling more efficient.


```{r education}
    # to combine the column values catagories 

    census_data$education = gsub("^10th", "No-college", census_data$education)
    census_data$education = gsub("^11th", "No-college", census_data$education)
    census_data$education = gsub("^12th", "No-college", census_data$education)
    census_data$education = gsub("^1st-4th", "No-college", census_data$education)
    census_data$education = gsub("^5th-6th", "No-college", census_data$education)
    census_data$education = gsub("^7th-8th", "No-college", census_data$education)
    census_data$education = gsub("^9th", "No-college", census_data$education)
    census_data$education = gsub("^Assoc-acdm", "Associates", census_data$education)
    census_data$education = gsub("^Assoc-voc", "Associates", census_data$education)
    census_data$education = gsub("^Bachelors", "Bachelors", census_data$education)
    census_data$education = gsub("^Doctorate", "Doctorate", census_data$education)
    census_data$education = gsub("^HS-Grad", "HS-Graduate", census_data$education)
    census_data$education = gsub("^Masters", "Masters", census_data$education)
    census_data$education = gsub("^Preschool", "No-college", census_data$education)
    census_data$education = gsub("^Prof-school", "Prof-School", census_data$education)
    census_data$education = gsub("^Some-college", "Some-college", census_data$education)
    
        # to display the data in a tabular form
    table(census_data$education) %>%
          kable() %>%
          kable_styling(latex_options = c("striped", "hover", "condensed"))

```
Please note: There is a weird space "^" is observed in education column values, so *gsub* is used to do string replace for values.

#### Combine Workclass column catagories

Next, categories in `workclass` column can be combined into fewer catogories as follows:


```{r workclass}
    # to combine the column values catagories 

    census_data$workclass = gsub("^Without-pay", "Not-Working", census_data$workclass)
    census_data$workclass = gsub("^Never-worked", "Not-Working", census_data$workclass)
    census_data$workclass = gsub("^Self-emp-not-inc", "Self-Employed", census_data$workclass)
    census_data$workclass = gsub("^Self-emp-inc", "Self-Employed", census_data$workclass)
    
        # to display the data in a tabular form
    table(census_data$workclass) %>%
          kable() %>%
          kable_styling(latex_options = c("striped", "hover", "condensed"))

```




\pagebreak

# 4. Exploratory Data Analysis and Visualization

The next step is to perform exploratory data analysis on the tidy data by utilizing visualization techniques.

#### Age vs income

The chart shows that users have a preference to rate movies rather higher than lower. 4.0 is the most common rating, followed by 3.0 and 5.0. 0.5 is the least preferable rating and there is no movie with a 0.0 rating.

The difference in the median and mean noted in the *Summary and Average Ratings* section above also supports the negative skewness slope of the distribution towards higher ratings.

```{r age_income}
    ggplot(census_data, aes(x = age, color = income, fill = income)) +
      geom_density(alpha = 0.8) +
      labs(x = "Age", y = "Density",
        title = "People who are older earn more",
        subtitle = "Density plot"
      )

    census_data %>%
      dplyr::group_by(income) %>%
      dplyr::summarise(age = median(age))
```

#### Workclass vs income

```{r workclass_income}
  
    plot_order <-
      reorder(census_data$workclass, census_data$workclass, length)
    plot_order <-
      factor(plot_order, levels = rev(levels(plot_order)))
    
    ggplot(census_data, aes(plot_order)) +
      geom_bar(aes(fill = income), color = "#1380A1", alpha = 0.5) +
      scale_fill_manual(values = c('#FC4E07','#00AFBB')) +
    
      # scale axis to custom range and intervels
      #scale_y_discrete(limits = c(seq(0,30000,1000))) 
  
      coord_flip() +  
      # to provide a title, x, and y axis labels
      labs(x = "Working Class", y = "Count",
        title = "Income bias based on working class")
  
    prop.table(table(census_data$workclass, census_data$income), 1) * 100

 
```


#### Education vs income

```{r education_income}
    plot_order <-
      reorder(census_data$education, census_data$education, length)
    plot_order <-
      factor(plot_order, levels = rev(levels(plot_order)))
    
    ggplot(census_data, aes(plot_order)) +
      geom_bar(aes(fill = income), color = "#1380A1", alpha = 0.8) +
      coord_flip() +
     labs(x = "Education Level", y = "Count", title = "People with more education earn more")
    
    prop.table(table(census_data$education, census_data$income), 1) * 100

```


#### Marital Status vs income

```{r maritalstatus_income}
    plot_order <-
      reorder(census_data$marital_status, census_data$marital_status, length)
    plot_order <-
      factor(plot_order, levels = rev(levels(plot_order)))
    
    ggplot(census_data, aes(plot_order)) +
      geom_bar(aes(fill = income), color = "#1380A1", alpha = 0.8) +
      coord_flip() +
       labs(x = "Marital Status", y = "Count", title = "Married people tend to earn more")

    
    prop.table(table(census_data$marital_status, census_data$income), 1) * 100

```


#### Race vs income

```{r Race_income}
    plot_order <-
      reorder(census_data$race, census_data$race, length)
    plot_order <-
      factor(plot_order, levels = rev(levels(plot_order)))
    
    ggplot(census_data, aes(plot_order)) +
      geom_bar(aes(fill = income), color = "#1380A1", alpha = 0.8) +
      coord_flip() +
   labs(x = "Race", y = "Count", title = "There is a bias in income based on race")


    prop.table(table(census_data$race, census_data$income), 1) * 100

```



#### Occupation vs income

```{r Occupation_income}
    plot_order <-
      reorder(census_data$occupation, census_data$occupation, length)
    plot_order <-
      factor(plot_order, levels = rev(levels(plot_order)))
    
    ggplot(census_data, aes(plot_order)) +
      geom_bar(aes(fill = income), color = "#1380A1", alpha = 0.8) +
      coord_flip() +
      labs(x = "Occupation", y = "Count", title = "There is a bias in the income based on occupation")
    
    prop.table(table(census_data$occupation, census_data$income), 1) * 100

```



#### Sex vs income

```{r Sex_income}
    plot_order <-
      reorder(census_data$sex, census_data$sex, length)
    plot_order <-
      factor(plot_order, levels = rev(levels(plot_order)))
    
    ggplot(census_data, aes(plot_order)) +
      geom_bar(aes(fill = income), color = "#1380A1", alpha = 0.8) +
      coord_flip() +
      labs(x = "Gender", y = "Count", title = "Men earn more")


    prop.table(table(census_data$sex, census_data$income), 1) * 100

```


#### Working hours vs income

```{r hours_income}
    ggplot(census_data, aes(x = hours_per_week, fill = income, color = income)) +
       geom_bar(alpha = 0.8, position = "fill") +
         coord_flip() +
   labs(x = "Hours per Week", y = "Proportion", title = "Men earn more")
    
census_data %>% 
   dplyr::group_by(income) %>% 
   dplyr::summarise(hours = mean(hours_per_week))

```


#### Native Country vs income

```{r country_income}

    plot_order <-
      reorder(census_data$native_country, census_data$native_country, length)
    plot_order <-
      factor(plot_order, levels = rev(levels(plot_order)))
    
    ggplot(census_data, aes(plot_order)) +
      geom_bar(aes(fill = income), color = "#1380A1", alpha = 0.8) +
      coord_flip() +
      labs(x = "Native Country", y = "Count", 
          title = "There is a bias in income based on the country of origin")
      
prop.table(table(census_data$native_country, census_data$income), 1) * 100

```

#### Outliers

Outliers are the datapoints that differs significantly from other observations. It may be due to variability in the measurement or due to data error. The larger outliers have a disproportionately large effect on model performance; hence, it is advisable to exclude them from dataset.


#### Outliers: Education level



```{r age_edul}
    census_data %>%
    
    # to map age and education level variables to aesthetics of ggplot function
    ggplot(aes(age, education)) +
    # to plot scattered data using geom_point
    geom_point( alpha = 0.3, col = "#00AFBB") +
    # to highlight obscure outlier points with different color
    geom_point(aes(col = (age<= 20 & education == 'Masters')), alpha = 1) +
    scale_colour_manual(values = setNames(c('red','#00AFBB'),c(T, F)))+
    # to move legend at the end of the figure
    theme(legend.position="bottom") +
    # to scale the axis values
    scale_x_continuous(breaks = seq(0,100,10))+
    # to provide a title, x, and y axis labels
    xlab("Age") + 
    ylab("Education Level") +
    ggtitle("Age vs Education Level")
```  


```{r filter_age_edul}
    census_data <- census_data %>%
      filter(!(age <= 20 & education == 'Masters'))
```  

#### Outliers: 

```{r sex_rel}
    census_data %>%
    # to map sex and relationship variables to aesthetics of ggplot function
    ggplot(aes(sex, relationship)) +
    # to plot scattered data using geom_point
    geom_point( alpha = 0.5, col = "#00AFBB") +
    # to highlight obscure outlier points with different color
    geom_point(aes(col = (sex == 'Male' & relationship == 'Wife') 
                   | (sex == 'Female' & relationship == 'Husband')), alpha = 1)+
    scale_colour_manual(values = setNames(c('red','#00AFBB'),c(T, F)))+
    # to move legend at the end of the figure  
    theme(legend.position="bottom") +
    
    # to provide a title, x, and y axis labels
    xlab("Sex") + 
    ylab("Relationship") +
    ggtitle("Gender vs Relationship")
```  


```{r filter_sex_rel}
    census_data <- census_data %>%
      filter(!((sex == 'Male' & relationship == 'Wife') 
                   | (sex == 'Female' & relationship == 'Husband')))
```  


#### Outliers: 

```{r age_hours}
    census_data %>%
    # to map age and hours per week variables to aesthetics of ggplot function
    ggplot(aes(age, hours_per_week)) +
    # to plot scattered data using geom_point
    geom_point( alpha = 0.3, col = "#00AFBB") +
    # to highlight obscure outlier points with different color  
    geom_point(aes(col = (age >= 80 & hours_per_week >40)),alpha = 1)+
    scale_colour_manual(values = setNames(c('red','#00AFBB'),c(T, F)))+
    # to scale the axis values
    scale_x_continuous(breaks = seq(0,100,10))+
    scale_y_continuous(breaks = seq(0,100,10))+
    # to move legend at the end of the figure  
    theme(legend.position="bottom") +
  
    # to provide a title, x, and y axis labels
    xlab("Age") + 
    ylab("Hours per week") +
    ggtitle("Age vs Hours per week")
``` 


```{r filter_age_hours}
    census_data <- census_data %>%
      filter(!(age >= 80 & hours_per_week >40))
```  


#### Outliers: 

```{r age_capital}
    census_data %>%
    # to map age and capital variables to aesthetics of ggplot function
    ggplot(aes(age, capital)) +
    
    # to plot scattered data using geom_point
    geom_point(alpha = 0.3, col = "#00AFBB") +
    # to highlight obscure outlier points with different color   
    geom_point(aes(col = (capital >= 99999)), alpha = 1)+
    scale_colour_manual(values = setNames(c('red','#00AFBB'),c(T, F)))+
    # to scale the axis values  
    scale_x_continuous(breaks = seq(0,100,10))+
    # to move legend at the end of the figure  
    theme(legend.position="bottom") +
    
    # to provide a title, x, and y axis labels
    xlab("Age") + 
    ylab("Capital") +
    ggtitle("Age vs Capital")
``` 


```{r filter_age_capital}
    census_data <- census_data %>%
      filter(!(capital >= 99999))
```  


\pagebreak

# 5. Modeling Approach

Now, with the analysis we are ready for modeling the prediction model, this section describes modeling approaches and insights gained before finalizing a target model.

### 5.1 Spliting dataset: Training and Validation Sets

Let's first split the census_data datasetinto *census_data_train* and *census_data_test* set (20%). The algorithm is developed using the census_data_train and for a final test of the algorithm, income will be predicted on the census_data_test set as if they were unknown. 

The following code is used to generate the required datasets. 

```{r factorizing}
    # to factoring variables to exclude the unwanted levels
    census_data$workclass <- factor(census_data$workclass)
    census_data$occupation <- factor(census_data$occupation)
    census_data$native_country <- factor(census_data$native_country)
    census_data$education <- factor(census_data$education)
    census_data$marital_status <- factor(census_data$marital_status)
    
    #census_data$hours_per_week <- factor(census_data$hours_per_week)
    #census_data$age <- factor(census_data$age)
    #census_data$capital <- factor(census_data$capital)
    
          anyNA(census_data)
          
        # next remove rows with missing values
    census_data <- na.omit(census_data)

``` 



```{r split datasets}
    ##############################################################################    
    # to split datasets into edx, validation, census_data_train, and test_set
    ##############################################################################
    set.seed(1)
    # Partition the data set into census_data_train and census_data_test dataset
    # with respect to dependent variable income
    # The census_data_test set will be 10% of census_data
    test_index <- createDataPartition(census_data$income,
                                      times = 1, p = 0.8, list = FALSE)
    census_data_train <- census_data[test_index, ]
    census_data_test  <- census_data[-test_index, ]
    # Remove unused objects from the memory
    rm(test_index)
```


<br/>

\pagebreak



### 5.2 Model 1: Logistic Regression Model

```{r log_model}
    # to create logistic regression model
    log_model <- glm(income ~ ., data = census_data_train, family = binomial)

    #summary(log_model)
    
    predicted <- predict(log_model, newdata = census_data_test, type = "response")
    predicted_class <- ifelse(predicted >= 0.5, ">50K", "<=50K")
    table(predicted_class)
    
    proportions <- addmargins(table(census_data_test$income, predicted_class))
    #log_model_Acc <- confusionMatrix(predicted_class, census_data_test$income)$overall[1]
    #log_model_Acc
    
    round(((4190  +830)/(4190  +830+640  +338))*100, digits=2)
    
    #Accuracy is 0.8524 on testing set.
```


```{r Accuracy_results, eval= FALSE}
      # to display Model Accuracy results in a tabular form
      model_results <- tibble(Model = "Logistic Regression Model", 
                             Dataset = "census_data_test", Accuracy = round(log_model_Acc, digits = 5))
      model_results %>% 
      
      # to apply theme to the table
      kable("latex", booktabs = T) %>% 
      kable_styling(latex_options = c("striped", "hover", "condensed")) %>%
      
      row_spec(1:1, bold = T, color = "white", background = "#D7261E")
```



### 5.3 Model 2: Random Forest

```{r rf_model}
    # to create logistic regression model

    set.seed(32423)
    rf_model <- randomForest(income ~ ., data = census_data_train)
    print(rf_model)
    
    Prediction3 <-
      predict(rf_model, newdata = census_data_test[, -15], type = 'class')
    
    rf_model_Acc <-
      confusionMatrix(Prediction3, census_data_test$income)$overall[1]
    
    rf_model_Acc

    
```


### 5.3 Model 3: KNN

```{r knn_model, eval=FALSE}
    # to create logistic regression model
    log_model <- glm(income ~ ., data = census_data_train, family = "binomial")
    summary(log_model)
    
    
    predicted <- predict(log_model, newdata = census_data_test, type = "response")
    predicted_class <- ifelse(predicted > 0.5, ">50K", "<=50K")
    proportions <- addmargins(table(census_data_test$income, predicted_class))
    log_model_Acc <- confusionMatrix(predicted_class, census_data_test$income, positive = ">50K")
    log_model_Acc
    #Accuracy is 0.8524 on testing set.
    
    
    Adult.model <- model.matrix(income~.-1,Adult)
model.train <- Adult.model[train,]
model.test <- Adult.model[-train,]
income.train <- income[train]
income.test <- income[-train]
set.seed(1)
knn.fit1 <- knn(census_data_train, census_data_test, income.train, k = 5)
knn.table1 <- table(knn.fit1,income.test)
knn.acc1 <- mean(knn.fit1==Adult.test$income)
knn.acc1
    
```

<br/>

# 6. Results
### 6.1 Modeling result comparison and performance

The result of RMSE derived from various models is listed below. As we can clearly see there is an improvement as we moved from the basic Average Rating model to the Regularized model. From all the models explored in this project, the **regularized Movie and User Effects model** seems to be the best and the finally proposed model with the lowest RMSE (highlighted in green).

```{r results, eval = FALSE}
      # to display result tables with RMSE model results 
      rmse_results %>% 
      kable("latex", booktabs = T) %>% 
      kable_styling(latex_options = c("striped", "hover", "condensed")) %>%
      pack_rows("Basic Prediction Model", 1, 1) %>%
      pack_rows("Single Predictor Model", 2, 5)  %>%
      pack_rows("Multipe Predictors Model", 6, 6) %>%
      pack_rows("Regularized Model", 7, 8) %>%
      row_spec(0, bold = T) %>%
      row_spec(8:8, bold = T, color = "white", background = "#3DDB48")

```


<br/>

# 7. Conclusion
### 7.1 Brief summary

The main aim of the project is to develop a recommendation system to predict movie ratings. The provided 10M Adult Census Income dataset is a real-world challenge that seasoned data scientists would have handled. From data setup, data wrangling as well as exploratory analysis and ggplot based visualization graphs to various modeling approaches, the concepts learned throughout the series of courses are implemented. 

Initially, basic prediction models including Rating Mean and single predictors based models are developed, later more complex multiple predictors models are attempted and finally **regularized Movie and User Effect predictive model** is implemented. A RMSE value of **`r ` ** is attained on validation set which is less than the targeted value.
 
### 7.2 Future work
The model using the Movie and User effects seems to have the best performance among the other two predictor models; however, multiple combinations of more than two potential predictors can be explored for further improvements as future work. 
For example, *Genre-specific* effect on a user preference to rate a movie can be further explored. If a user rates movies with Drama genre high, the *Drama* effect for that user can be taken into account while predicting rating as the user is more likely to give higher ratings to movies with Drama as a sub-genre in combined genre Drama|Comedy and vice-versa.
Such a genre-specific effect can be used along with Movie and User Effects for further improvement. 
Furthermore, Other more complex modeling approaches such as XGBoost, NNET, etc could be used to further improve the performance.
### 7.3 Limitations 
Initially, k-fold cross-validation with k=10 was planned; however, due to computing resource constraint it was not successful. So, a simpler alternative approach to partition provided edx dataset into training and test sets are utilized.
Also, due to the constraint, more sophisticated models with higher performance didn't succeed and thus not included in this report. Those would require powerful computing machines. 
One such example is splitting single pipe-delimited concatenated `genres` categories into single categories and use it in genre-specific effect, mentioned in '*Future Work* section'. However, the target RMSE was achieved with the Regularized Movie and User Effect model implemented in the project.
<br/>
\pagebreak

# 8. References
* Data Science textbook by Rafael Irizarry
    + [Chapter 34.7 Recommendation systems](https://rafalab.github.io/dsbook/large-datasets.html#recommendation-systems)
    + [Chapter 34.9 Regularization](https://rafalab.github.io/dsbook/large-datasets.html#regularization)
* UCI
    + Adult Census Income Dataset: http://archive.ics.uci.edu/ml/machine-learning-databases/adult

# 9. Github Repo
* https://github.com/jha-r/Harvardx-PH125.9x-Capstone-Census_Income_CYO
```{r memory cleanup, echo = FALSE, results = "hide"}
      # Remove objects    
      rm(Married, Notmarried, LatinAmerica, SouthAmerica, Europe, Asia, SE_Aisa, US, UK, Canada, l)  
      # Call Garbage Collector
      gc()
```

# TODO
write up
code comments 
grammar
